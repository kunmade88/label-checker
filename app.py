import streamlit as st
import cv2
import numpy as np
import pytesseract
import pandas as pd
from pdf2image import convert_from_bytes
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¼ë²¨ ì²´í¬ AI ì •ë°€ ë¶„ì„", layout="wide")

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def get_clean_image(uploaded_file):
    """ë°°ê²½ì€ ì™„ì „ í°ìƒ‰, ê¸€ìëŠ” ì§„í•œ ê²€ì •ìƒ‰ìœ¼ë¡œ ë³€í™˜"""
    file_bytes = uploaded_file.read()
    if uploaded_file.name.lower().endswith('.pdf'):
        pages = convert_from_bytes(file_bytes, dpi=300)
        img = np.array(pages[0].convert('RGB'))
    else:
        nparr = np.frombuffer(file_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    dist = cv2.fastNlMeansDenoising(gray, h=10)
    # OTSU ì´ì§„í™”ë¡œ ë°°ê²½ê³¼ ê¸€ì ë¶„ë¦¬
    _, binary = cv2.threshold(dist, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    if np.mean(binary) < 127: # ë°°ê²½ì´ ì–´ë‘ìš°ë©´ ë°˜ì „
        binary = cv2.bitwise_not(binary)
    return cv2.cvtColor(binary, cv2.COLOR_GRAY2RGB)

def clean_for_match(text, is_ocr=False):
    if not text: return ""
    # ì „ì„±ë¶„/Ingredients ì œëª© ì œì™¸
    if is_ocr:
        text = re.sub(r'ì „ì„±ë¶„|Ingredients|INGREDIENTS|ì¸ê·¸ë¦¬ë””ì–¸íŠ¸|ì „ ì„± ë¶„', '', str(text))
    # ë§¤ì¹­ìš© ì•Œë§¹ì´ (ê¸°í˜¸ ì œê±°)
    return re.sub(r'[^a-zA-Z0-9ê°€-í£]', '', text).lower().strip()

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("ğŸ› ï¸ ì‘ì—… ëª¨ë“œ")
    mode = st.radio("ë¶„ì„ ìœ í˜•", ["Excel vs PDF (ì„±ë¶„ ê²€ì¦)", "PDF vs PDF (ì‹œê°ì  ì°¨ì´)"])
    if mode == "Excel vs PDF (ì„±ë¶„ ê²€ì¦)":
        lang_choice = st.radio("ê²€ì¦ ì–¸ì–´", ["ì˜ë¬¸ëª…", "í•œê¸€ëª…"])
        compare_limit = st.number_input("ë¹„êµ ì„±ë¶„ ê°œìˆ˜", value=26)

# --- ëª¨ë“œ 1: Excel vs PDF ---
if mode == "Excel vs PDF (ì„±ë¶„ ê²€ì¦)":
    st.title("ğŸ” ë¬¸ì•ˆ ì „ì„±ë¶„ ê²€í†  í…ŒìŠ¤íŠ¸ ìš©í›ˆ")
    
    col1, col2 = st.columns(2)
    with col1:
        excel_file = st.file_uploader("ğŸ“‚ ê¸°ì¤€ ì—‘ì…€ ì—…ë¡œë“œ", type=['xlsx', 'csv'])
    with col2:
        pdf_file = st.file_uploader("ğŸ“„ ê²€í†  PDF/ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=['pdf', 'jpg', 'png'])

    if excel_file and pdf_file:
        st.markdown("---")
        view_c1, view_c2 = st.columns(2)
        
        with view_c1:
            st.subheader("ğŸ“Š ì—‘ì…€ ë°ì´í„°")
            df_raw = pd.read_excel(excel_file) if excel_file.name.endswith('.xlsx') else pd.read_csv(excel_file)
            header_idx = next((i for i, row in df_raw.iterrows() if "No." in row.values), 0)
            df_display = pd.read_excel(excel_file, skiprows=header_idx + 1).head(int(compare_limit))
            st.dataframe(df_display, height=600, use_container_width=True)

        with view_c2:
            st.subheader("ğŸ–¼ï¸ ê°€ë…ì„± ìµœì í™” ì´ë¯¸ì§€")
            processed_img = get_clean_image(pdf_file)
            st.image(processed_img, use_container_width=True)

        if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", use_container_width=True):
            # OCR ìˆ˜í–‰ ë° ì›ë¬¸ ë°ì´í„° ë³´ì¡´
            ocr_text = pytesseract.image_to_string(processed_img, lang='kor+eng')
            # ì‰¼í‘œ(,) ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œì„œ ë¦¬ìŠ¤íŠ¸í™” (ì´ë¯¸ì§€ì˜ ì‹¤ì œ ì „ì„±ë¶„ ìˆœì„œ ì¶”ì ìš©)
            raw_ocr_parts = [p.strip() for p in ocr_text.replace('\n', ' ').split(',') if p.strip()]

            standard_list = df_display[lang_choice].dropna().astype(str).tolist()
            comparison = []
            
            # ë§¤ì¹­ ë¡œì§
            compact_ocr_blob = clean_for_match(ocr_text, is_ocr=True)
            search_area = compact_ocr_blob

            for i, std_name in enumerate(standard_list):
                clean_std = clean_for_match(std_name)
                detected_text = "ë¯¸ê²€ì¶œ" # ê¸°ë³¸ê°’
                
                if clean_std and clean_std in search_area:
                    status = "âœ… ì¼ì¹˜"
                    # ì‹¤ì œ PDFì—ì„œ ì–´ë–»ê²Œ ì½í˜”ëŠ”ì§€ ê°€ì¥ ìœ ì‚¬í•œ ì¡°ê°ì„ ì°¾ì•„ ê¸°ë¡
                    # (ë‹¨ìˆœ êµ¬í˜„ì„ ìœ„í•´ ì—‘ì…€ ì´ë¦„ê³¼ ê°€ì¥ ë‹®ì€ OCR ì¡°ê° ì¶”ì¶œ)
                    pos = search_area.find(clean_std)
                    search_area = search_area[pos + len(clean_std):]
                    detected_text = std_name # ì¼ì¹˜í•  ê²½ìš° ì—‘ì…€ëª… í‘œì‹œ
                else:
                    status = "âŒ ì˜¤ë¥˜"
                    # ì˜¤ë¥˜ì¼ ê²½ìš°, í˜„ì¬ search_areaì˜ ì•ë¶€ë¶„ ì¼ë¶€ë¥¼ ë³´ì—¬ì¤Œ (ë­ê°€ ìˆëŠ”ì§€ í™•ì¸ìš©)
                    detected_text = f"(ì¶”ì •): {ocr_text.split(',')[i] if i < len(ocr_text.split(',')) else 'ë°ì´í„° ì—†ìŒ'}"

                comparison.append({
                    "No": i+1,
                    "ì—‘ì…€ ê¸°ì¤€ (A)": std_name,
                    "PDF ê²€ì¶œ ë‚´ìš© (B)": detected_text,
                    "ìƒíƒœ": status
                })

            st.markdown("---")
            st.subheader("ğŸ“‹ ì„±ë¶„ ëŒ€ì¡° ê²°ê³¼ ë¦¬í¬íŠ¸")
            res_df = pd.DataFrame(comparison)
            
            # ìŠ¤íƒ€ì¼ ì •ì˜: Aì™€ Bê°€ ë‹¤ë¥¼ ê²½ìš° ê°•ì¡°
            def highlight_diff(row):
                if row['ìƒíƒœ'] == "âŒ ì˜¤ë¥˜":
                    return ['background-color: #f8d7da'] * len(row)
                return ['background-color: #d4edda'] * len(row)

            st.dataframe(res_df.style.apply(highlight_diff, axis=1), use_container_width=True, height=600)

# --- ëª¨ë“œ 2: PDF vs PDF ---
elif mode == "PDF vs PDF (ì‹œê°ì  ì°¨ì´)":
    st.title("ğŸ–¼ï¸ ë¬¸ì•ˆê²€í†  ìˆ˜ì •ì „/í›„ ë¹„êµ í…ŒìŠ¤íŠ¸ ìš©í›ˆ")
    # (ì´ì „ì˜ ì‹œê°ì  ì°¨ì´ ë¶„ì„ ì½”ë“œì™€ ë™ì¼í•˜ì—¬ ìœ ì§€ë©ë‹ˆë‹¤)
    f_old = st.file_uploader("ì›ë³¸ ì—…ë¡œë“œ", type=['pdf', 'jpg', 'png'], key="old")
    f_new = st.file_uploader("ìˆ˜ì •ë³¸ ì—…ë¡œë“œ", type=['pdf', 'jpg', 'png'], key="new")
    if f_old and f_new:
        if st.button("ğŸ” ì°¨ì´ì  ë¶„ì„ ì‹¤í–‰"):
            img_old = get_clean_image(f_old)
            img_new = get_clean_image(f_new)
            h, w, _ = img_new.shape
            img_old = cv2.resize(img_old, (w, h))
            diff = cv2.absdiff(cv2.cvtColor(img_old, cv2.COLOR_RGB2GRAY), cv2.cvtColor(img_new, cv2.COLOR_RGB2GRAY))
            _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            output = img_new.copy()
            for cnt in contours:
                if cv2.contourArea(cnt) > 50:
                    x, y, w_b, h_b = cv2.boundingRect(cnt)
                    cv2.rectangle(output, (x, y), (x + w_b, y + h_b), (255, 0, 0), 2)
            st.image(output, use_container_width=True)